# üìä An√°lise Completa do Modelo de Regress√£o Linear

## üéØ O que vamos implementar:

1. **Histograma dos res√≠duos** (dados de treinamento)
2. **Gr√°ficos de dispers√£o** (real vs predito para treino e teste)
3. **Coeficientes de correla√ß√£o** (treino e teste)
4. **An√°lise e coment√°rios** sobre os resultados

---

## üîß IMPLEMENTA√á√ÉO COMPLETA

### **PASSO 1: Preparar e Treinar o Modelo**

```python
# Importar bibliotecas necess√°rias
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from scipy.stats import pearsonr, shapiro
import warnings
warnings.filterwarnings('ignore')

# Configura√ß√µes de visualiza√ß√£o
plt.style.use('default')
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 12

# Carregar dados
df = pd.read_excel('Real estate valuation data set.xlsx')

# Separar features (X) e target (Y)
X = df.iloc[:, :-1]  # Todas as colunas exceto a √∫ltima
y = df.iloc[:, -1]   # √öltima coluna (pre√ßo)

# Dividir em treino (80%) e teste (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalizar os dados
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("=== INFORMA√á√ïES DOS DADOS ===")
print(f"Forma dos dados: {df.shape}")
print(f"Treino: {X_train.shape}")
print(f"Teste: {X_test.shape}")
print(f"Vari√°vel target: {y.name}")
print(f"Features: {list(X.columns)}")

# Treinar modelo de regress√£o linear
lr_model = LinearRegression()
lr_model.fit(X_train_scaled, y_train)

# Fazer predi√ß√µes
lr_train_pred = lr_model.predict(X_train_scaled)
lr_test_pred = lr_model.predict(X_test_scaled)

# Calcular m√©tricas b√°sicas
lr_train_r2 = r2_score(y_train, lr_train_pred)
lr_test_r2 = r2_score(y_test, lr_test_pred)

print(f"\n=== M√âTRICAS DO MODELO ===")
print(f"R¬≤ Treino: {lr_train_r2:.4f}")
print(f"R¬≤ Teste:  {lr_test_r2:.4f}")
```

---

## üìà PASSO 2: Histograma dos Res√≠duos (Dados de Treinamento)

```python
# Calcular res√≠duos (erros) para dados de treinamento
residuos_treino = y_train - lr_train_pred

# Criar figura com subplots
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# 1. Histograma dos res√≠duos
axes[0, 0].hist(residuos_treino, bins=30, alpha=0.7, color='skyblue', edgecolor='black', density=True)
axes[0, 0].set_title('Histograma dos Res√≠duos (Dados de Treinamento)', fontsize=14, fontweight='bold')
axes[0, 0].set_xlabel('Res√≠duos (Valor Real - Valor Predito)')
axes[0, 0].set_ylabel('Densidade')
axes[0, 0].grid(True, alpha=0.3)

# 2. Adicionar curva normal te√≥rica
from scipy.stats import norm
mu, sigma = norm.fit(residuos_treino)
x = np.linspace(residuos_treino.min(), residuos_treino.max(), 100)
y_normal = norm.pdf(x, mu, sigma)
axes[0, 0].plot(x, y_normal, 'r-', linewidth=2, label=f'Normal (Œº={mu:.2f}, œÉ={sigma:.2f})')
axes[0, 0].legend()

# 3. QQ-Plot para verificar normalidade
from scipy.stats import probplot
probplot(residuos_treino, dist="norm", plot=axes[0, 1])
axes[0, 1].set_title('Q-Q Plot dos Res√≠duos', fontsize=14, fontweight='bold')
axes[0, 1].grid(True, alpha=0.3)

# 4. Gr√°fico de res√≠duos vs preditos
axes[1, 0].scatter(lr_train_pred, residuos_treino, alpha=0.6, color='green')
axes[1, 0].axhline(y=0, color='red', linestyle='--', linewidth=2)
axes[1, 0].set_title('Res√≠duos vs Valores Preditos', fontsize=14, fontweight='bold')
axes[1, 0].set_xlabel('Valores Preditos')
axes[1, 0].set_ylabel('Res√≠duos')
axes[1, 0].grid(True, alpha=0.3)

# 5. Boxplot dos res√≠duos
axes[1, 1].boxplot(residuos_treino, patch_artist=True, boxprops=dict(facecolor='lightblue'))
axes[1, 1].set_title('Boxplot dos Res√≠duos', fontsize=14, fontweight='bold')
axes[1, 1].set_ylabel('Res√≠duos')
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Teste de normalidade (Shapiro-Wilk)
statistic, p_value = shapiro(residuos_treino)
print(f"\n=== TESTE DE NORMALIDADE (Shapiro-Wilk) ===")
print(f"Estat√≠stica: {statistic:.4f}")
print(f"P-valor: {p_value:.4f}")
print(f"Res√≠duos s√£o normais? {'SIM' if p_value > 0.05 else 'N√ÉO'} (Œ±=0.05)")

# Estat√≠sticas descritivas dos res√≠duos
print(f"\n=== ESTAT√çSTICAS DOS RES√çDUOS ===")
print(f"M√©dia: {np.mean(residuos_treino):.4f}")
print(f"Desvio padr√£o: {np.std(residuos_treino):.4f}")
print(f"M√≠nimo: {np.min(residuos_treino):.4f}")
print(f"M√°ximo: {np.max(residuos_treino):.4f}")
print(f"Assimetria: {pd.Series(residuos_treino).skew():.4f}")
print(f"Curtose: {pd.Series(residuos_treino).kurtosis():.4f}")
```

---

## üìä PASSO 3: Gr√°ficos de Dispers√£o (Real vs Predito)

```python
# Criar gr√°ficos de dispers√£o para treino e teste
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# Gr√°fico para dados de TREINO
axes[0].scatter(y_train, lr_train_pred, alpha=0.6, color='blue', s=50)
axes[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=3, label='Linha de Perfeita Predi√ß√£o')
axes[0].set_xlabel('Valor Real (Pre√ßo)', fontsize=12)
axes[0].set_ylabel('Valor Predito (Pre√ßo)', fontsize=12)
axes[0].set_title('TREINO: Real vs Predito\nRegress√£o Linear', fontsize=14, fontweight='bold')
axes[0].grid(True, alpha=0.3)
axes[0].legend()

# Adicionar R¬≤ no gr√°fico
axes[0].text(0.05, 0.95, f'R¬≤ = {lr_train_r2:.4f}', transform=axes[0].transAxes, 
              bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8),
              fontsize=12, verticalalignment='top')

# Gr√°fico para dados de TESTE
axes[1].scatter(y_test, lr_test_pred, alpha=0.6, color='green', s=50)
axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3, label='Linha de Perfeita Predi√ß√£o')
axes[1].set_xlabel('Valor Real (Pre√ßo)', fontsize=12)
axes[1].set_ylabel('Valor Predito (Pre√ßo)', fontsize=12)
axes[1].set_title('TESTE: Real vs Predito\nRegress√£o Linear', fontsize=14, fontweight='bold')
axes[1].grid(True, alpha=0.3)
axes[1].legend()

# Adicionar R¬≤ no gr√°fico
axes[1].text(0.05, 0.95, f'R¬≤ = {lr_test_r2:.4f}', transform=axes[1].transAxes, 
              bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8),
              fontsize=12, verticalalignment='top')

plt.tight_layout()
plt.show()

# Calcular erros para an√°lise
mse_treino = mean_squared_error(y_train, lr_train_pred)
mse_teste = mean_squared_error(y_test, lr_test_pred)
rmse_treino = np.sqrt(mse_treino)
rmse_teste = np.sqrt(mse_teste)
mae_treino = mean_absolute_error(y_train, lr_train_pred)
mae_teste = mean_absolute_error(y_test, lr_test_pred)

print(f"\n=== M√âTRICAS DE ERRO ===")
print(f"Treino - MSE: {mse_treino:.4f}, RMSE: {rmse_treino:.4f}, MAE: {mae_treino:.4f}")
print(f"Teste  - MSE: {mse_teste:.4f}, RMSE: {rmse_teste:.4f}, MAE: {mae_teste:.4f}")
```

---

## üîó PASSO 4: Coeficientes de Correla√ß√£o

```python
# Calcular correla√ß√µes de Pearson
corr_treino, p_valor_treino = pearsonr(y_train, lr_train_pred)
corr_teste, p_valor_teste = pearsonr(y_test, lr_test_pred)

# Calcular correla√ß√£o de Spearman (robusta a outliers)
from scipy.stats import spearmanr
corr_spearman_treino, p_spearman_treino = spearmanr(y_train, lr_train_pred)
corr_spearman_teste, p_spearman_teste = spearmanr(y_test, lr_test_pred)

# Criar tabela de correla√ß√µes
print("=== COEFICIENTES DE CORRELA√á√ÉO ===")
print("=" * 60)
print(f"{'M√©trica':<20} {'Treino':<15} {'Teste':<15}")
print("=" * 60)
print(f"{'Correla√ß√£o Pearson':<20} {corr_treino:<15.4f} {corr_teste:<15.4f}")
print(f"{'P-valor Pearson':<20} {p_valor_treino:<15.4f} {p_valor_teste:<15.4f}")
print(f"{'Correla√ß√£o Spearman':<20} {corr_spearman_treino:<15.4f} {corr_spearman_teste:<15.4f}")
print(f"{'P-valor Spearman':<20} {p_spearman_treino:<15.4f} {p_spearman_teste:<15.4f}")
print("=" * 60)

# Interpreta√ß√£o das correla√ß√µes
print(f"\n=== INTERPRETA√á√ÉO DAS CORRELA√á√ïES ===")
print(f"üìä Correla√ß√£o Treino: {corr_treino:.4f}")
if corr_treino >= 0.9:
    print("   ‚úÖ EXCELENTE: Correla√ß√£o muito forte")
elif corr_treino >= 0.8:
    print("   ‚úÖ MUITO BOM: Correla√ß√£o forte")
elif corr_treino >= 0.7:
    print("   ‚úÖ BOM: Correla√ß√£o moderadamente forte")
elif corr_treino >= 0.5:
    print("   ‚ö†Ô∏è  MODERADO: Correla√ß√£o moderada")
else:
    print("   ‚ùå BAIXO: Correla√ß√£o fraca")

print(f"\nüìä Correla√ß√£o Teste: {corr_teste:.4f}")
if corr_teste >= 0.9:
    print("   ‚úÖ EXCELENTE: Correla√ß√£o muito forte")
elif corr_teste >= 0.8:
    print("   ‚úÖ MUITO BOM: Correla√ß√£o forte")
elif corr_teste >= 0.7:
    print("   ‚úÖ BOM: Correla√ß√£o moderadamente forte")
elif corr_teste >= 0.5:
    print("   ‚ö†Ô∏è  MODERADO: Correla√ß√£o moderada")
else:
    print("   ‚ùå BAIXO: Correla√ß√£o fraca")
```

---

## üìù PASSO 5: An√°lise e Coment√°rios

```python
# Criar resumo executivo
print("\n" + "="*80)
print("üìã RESUMO EXECUTIVO - MODELO DE REGRESS√ÉO LINEAR")
print("="*80)

print(f"\nüéØ PERFORMANCE DO MODELO:")
print(f"   ‚Ä¢ R¬≤ Treino: {lr_train_r2:.4f}")
print(f"   ‚Ä¢ R¬≤ Teste:  {lr_test_r2:.4f}")
print(f"   ‚Ä¢ Diferen√ßa: {abs(lr_train_r2 - lr_test_r2):.4f}")

if abs(lr_train_r2 - lr_test_r2) < 0.05:
    print("   ‚úÖ Modelo est√°vel (pouca diferen√ßa treino/teste)")
else:
    print("   ‚ö†Ô∏è  Poss√≠vel overfitting (grande diferen√ßa treino/teste)")

print(f"\nüìä AN√ÅLISE DOS RES√çDUOS:")
print(f"   ‚Ä¢ M√©dia dos res√≠duos: {np.mean(residuos_treino):.4f} (deve ser pr√≥xima de 0)")
print(f"   ‚Ä¢ Desvio padr√£o: {np.std(residuos_treino):.4f}")
print(f"   ‚Ä¢ Normalidade (Shapiro-Wilk): {'SIM' if p_value > 0.05 else 'N√ÉO'}")

print(f"\nüîó CORRELA√á√ïES:")
print(f"   ‚Ä¢ Treino: {corr_treino:.4f}")
print(f"   ‚Ä¢ Teste:  {corr_teste:.4f}")

print(f"\nüí° INTERPRETA√á√ÉO GERAL:")
if lr_test_r2 >= 0.8 and corr_teste >= 0.8:
    print("   ‚úÖ EXCELENTE: Modelo muito bem ajustado aos dados")
elif lr_test_r2 >= 0.7 and corr_teste >= 0.7:
    print("   ‚úÖ BOM: Modelo bem ajustado aos dados")
elif lr_test_r2 >= 0.5 and corr_teste >= 0.5:
    print("   ‚ö†Ô∏è  MODERADO: Modelo com ajuste moderado")
else:
    print("   ‚ùå BAIXO: Modelo com ajuste insuficiente")

print("="*80)
```

---

## üéØ **RESPOSTAS AOS REQUISITOS:**

### **1. Histograma dos Res√≠duos:**
- ‚úÖ **Implementado** com curva normal te√≥rica
- ‚úÖ **Teste de normalidade** (Shapiro-Wilk)
- ‚úÖ **QQ-Plot** para verifica√ß√£o visual
- ‚úÖ **An√°lise de assimetria e curtose**

### **2. Gr√°ficos de Dispers√£o:**
- ‚úÖ **Treino vs Teste** lado a lado
- ‚úÖ **Linha de perfeita predi√ß√£o** (y=x)
- ‚úÖ **R¬≤** exibido em cada gr√°fico
- ‚úÖ **M√©tricas de erro** (MSE, RMSE, MAE)

### **3. Coeficientes de Correla√ß√£o:**
- ‚úÖ **Pearson e Spearman** para robustez
- ‚úÖ **P-valores** para signific√¢ncia estat√≠stica
- ‚úÖ **Interpreta√ß√£o autom√°tica** dos valores
- ‚úÖ **Compara√ß√£o treino vs teste**

### **4. An√°lise Completa:**
- ‚úÖ **Resumo executivo** com interpreta√ß√µes
- ‚úÖ **Detec√ß√£o de overfitting**
- ‚úÖ **Avalia√ß√£o da qualidade do ajuste**
- ‚úÖ **Coment√°rios sobre gaussianidade**

---

## üí° **COMO USAR:**

1. **Execute cada bloco** na ordem apresentada
2. **Analise os gr√°ficos** gerados
3. **Leia os coment√°rios** autom√°ticos
4. **Use o resumo executivo** para sua an√°lise

Este c√≥digo fornece uma an√°lise completa e profissional do modelo de regress√£o linear! üöÄ 