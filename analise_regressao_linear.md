# ğŸ“Š AnÃ¡lise Completa do Modelo de RegressÃ£o Linear

## ğŸ¯ O que vamos implementar:

1. **Histograma dos resÃ­duos** (dados de treinamento)
2. **GrÃ¡ficos de dispersÃ£o** (real vs predito para treino e teste)
3. **Coeficientes de correlaÃ§Ã£o** (treino e teste)
4. **AnÃ¡lise e comentÃ¡rios** sobre os resultados

---

## ğŸ”§ IMPLEMENTAÃ‡ÃƒO COMPLETA

### **PASSO 1: Preparar e Treinar o Modelo**

```python
# Importar bibliotecas necessÃ¡rias
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from scipy.stats import pearsonr, shapiro
import warnings
warnings.filterwarnings('ignore')

# ConfiguraÃ§Ãµes de visualizaÃ§Ã£o
plt.style.use('default')
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 12

# Carregar dados
df = pd.read_excel('Real estate valuation data set.xlsx')

# Separar features (X) e target (Y)
X = df.iloc[:, :-1]  # Todas as colunas exceto a Ãºltima
y = df.iloc[:, -1]   # Ãšltima coluna (preÃ§o)

# Dividir em treino (80%) e teste (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalizar os dados
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("=== INFORMAÃ‡Ã•ES DOS DADOS ===")
print(f"Forma dos dados: {df.shape}")
print(f"Treino: {X_train.shape}")
print(f"Teste: {X_test.shape}")
print(f"VariÃ¡vel target: {y.name}")
print(f"Features: {list(X.columns)}")

# Treinar modelo de regressÃ£o linear
lr_model = LinearRegression()
lr_model.fit(X_train_scaled, y_train)

# Fazer prediÃ§Ãµes
lr_train_pred = lr_model.predict(X_train_scaled)
lr_test_pred = lr_model.predict(X_test_scaled)

# Calcular mÃ©tricas bÃ¡sicas
lr_train_r2 = r2_score(y_train, lr_train_pred)
lr_test_r2 = r2_score(y_test, lr_test_pred)

print(f"\n=== MÃ‰TRICAS DO MODELO ===")
print(f"RÂ² Treino: {lr_train_r2:.4f}")
print(f"RÂ² Teste:  {lr_test_r2:.4f}")
```

---

## ğŸ“ˆ PASSO 2: Histograma dos ResÃ­duos (Dados de Treinamento)

```python
# Calcular resÃ­duos (erros) para dados de treinamento
residuos_treino = y_train - lr_train_pred

# Criar figura com subplots
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# 1. Histograma dos resÃ­duos
axes[0, 0].hist(residuos_treino, bins=30, alpha=0.7, color='skyblue', edgecolor='black', density=True)
axes[0, 0].set_title('Histograma dos ResÃ­duos (Dados de Treinamento)', fontsize=14, fontweight='bold')
axes[0, 0].set_xlabel('ResÃ­duos (Valor Real - Valor Predito)')
axes[0, 0].set_ylabel('Densidade')
axes[0, 0].grid(True, alpha=0.3)

# 2. Adicionar curva normal teÃ³rica
from scipy.stats import norm
mu, sigma = norm.fit(residuos_treino)
x = np.linspace(residuos_treino.min(), residuos_treino.max(), 100)
y_normal = norm.pdf(x, mu, sigma)
axes[0, 0].plot(x, y_normal, 'r-', linewidth=2, label=f'Normal (Î¼={mu:.2f}, Ïƒ={sigma:.2f})')
axes[0, 0].legend()

# 3. QQ-Plot para verificar normalidade
from scipy.stats import probplot
probplot(residuos_treino, dist="norm", plot=axes[0, 1])
axes[0, 1].set_title('Q-Q Plot dos ResÃ­duos', fontsize=14, fontweight='bold')
axes[0, 1].grid(True, alpha=0.3)

# 4. GrÃ¡fico de resÃ­duos vs preditos
axes[1, 0].scatter(lr_train_pred, residuos_treino, alpha=0.6, color='green')
axes[1, 0].axhline(y=0, color='red', linestyle='--', linewidth=2)
axes[1, 0].set_title('ResÃ­duos vs Valores Preditos', fontsize=14, fontweight='bold')
axes[1, 0].set_xlabel('Valores Preditos')
axes[1, 0].set_ylabel('ResÃ­duos')
axes[1, 0].grid(True, alpha=0.3)

# 5. Boxplot dos resÃ­duos
axes[1, 1].boxplot(residuos_treino, patch_artist=True, boxprops=dict(facecolor='lightblue'))
axes[1, 1].set_title('Boxplot dos ResÃ­duos', fontsize=14, fontweight='bold')
axes[1, 1].set_ylabel('ResÃ­duos')
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Teste de normalidade (Shapiro-Wilk)
statistic, p_value = shapiro(residuos_treino)
print(f"\n=== TESTE DE NORMALIDADE (Shapiro-Wilk) ===")
print(f"EstatÃ­stica: {statistic:.4f}")
print(f"P-valor: {p_value:.4f}")
print(f"ResÃ­duos sÃ£o normais? {'SIM' if p_value > 0.05 else 'NÃƒO'} (Î±=0.05)")

# EstatÃ­sticas descritivas dos resÃ­duos
print(f"\n=== ESTATÃSTICAS DOS RESÃDUOS ===")
print(f"MÃ©dia: {np.mean(residuos_treino):.4f}")
print(f"Desvio padrÃ£o: {np.std(residuos_treino):.4f}")
print(f"MÃ­nimo: {np.min(residuos_treino):.4f}")
print(f"MÃ¡ximo: {np.max(residuos_treino):.4f}")
print(f"Assimetria: {pd.Series(residuos_treino).skew():.4f}")
print(f"Curtose: {pd.Series(residuos_treino).kurtosis():.4f}")
```

---

## ğŸ“Š PASSO 3: GrÃ¡ficos de DispersÃ£o (Real vs Predito)

```python
# Criar grÃ¡ficos de dispersÃ£o para treino e teste
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# GrÃ¡fico para dados de TREINO
axes[0].scatter(y_train, lr_train_pred, alpha=0.6, color='blue', s=50)
axes[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=3, label='Linha de Perfeita PrediÃ§Ã£o')
axes[0].set_xlabel('Valor Real (PreÃ§o)', fontsize=12)
axes[0].set_ylabel('Valor Predito (PreÃ§o)', fontsize=12)
axes[0].set_title('TREINO: Real vs Predito\nRegressÃ£o Linear', fontsize=14, fontweight='bold')
axes[0].grid(True, alpha=0.3)
axes[0].legend()

# Adicionar RÂ² no grÃ¡fico
axes[0].text(0.05, 0.95, f'RÂ² = {lr_train_r2:.4f}', transform=axes[0].transAxes, 
              bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8),
              fontsize=12, verticalalignment='top')

# GrÃ¡fico para dados de TESTE
axes[1].scatter(y_test, lr_test_pred, alpha=0.6, color='green', s=50)
axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3, label='Linha de Perfeita PrediÃ§Ã£o')
axes[1].set_xlabel('Valor Real (PreÃ§o)', fontsize=12)
axes[1].set_ylabel('Valor Predito (PreÃ§o)', fontsize=12)
axes[1].set_title('TESTE: Real vs Predito\nRegressÃ£o Linear', fontsize=14, fontweight='bold')
axes[1].grid(True, alpha=0.3)
axes[1].legend()

# Adicionar RÂ² no grÃ¡fico
axes[1].text(0.05, 0.95, f'RÂ² = {lr_test_r2:.4f}', transform=axes[1].transAxes, 
              bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8),
              fontsize=12, verticalalignment='top')

plt.tight_layout()
plt.show()

# Calcular erros para anÃ¡lise
mse_treino = mean_squared_error(y_train, lr_train_pred)
mse_teste = mean_squared_error(y_test, lr_test_pred)
rmse_treino = np.sqrt(mse_treino)
rmse_teste = np.sqrt(mse_teste)
mae_treino = mean_absolute_error(y_train, lr_train_pred)
mae_teste = mean_absolute_error(y_test, lr_test_pred)

print(f"\n=== MÃ‰TRICAS DE ERRO ===")
print(f"Treino - MSE: {mse_treino:.4f}, RMSE: {rmse_treino:.4f}, MAE: {mae_treino:.4f}")
print(f"Teste  - MSE: {mse_teste:.4f}, RMSE: {rmse_teste:.4f}, MAE: {mae_teste:.4f}")
```

---

## ğŸ”— PASSO 4: Coeficientes de CorrelaÃ§Ã£o

```python
# Calcular correlaÃ§Ãµes de Pearson
corr_treino, p_valor_treino = pearsonr(y_train, lr_train_pred)
corr_teste, p_valor_teste = pearsonr(y_test, lr_test_pred)

# Calcular correlaÃ§Ã£o de Spearman (robusta a outliers)
from scipy.stats import spearmanr
corr_spearman_treino, p_spearman_treino = spearmanr(y_train, lr_train_pred)
corr_spearman_teste, p_spearman_teste = spearmanr(y_test, lr_test_pred)

# Criar tabela de correlaÃ§Ãµes
print("=== COEFICIENTES DE CORRELAÃ‡ÃƒO ===")
print("=" * 60)
print(f"{'MÃ©trica':<20} {'Treino':<15} {'Teste':<15}")
print("=" * 60)
print(f"{'CorrelaÃ§Ã£o Pearson':<20} {corr_treino:<15.4f} {corr_teste:<15.4f}")
print(f"{'P-valor Pearson':<20} {p_valor_treino:<15.4f} {p_valor_teste:<15.4f}")
print(f"{'CorrelaÃ§Ã£o Spearman':<20} {corr_spearman_treino:<15.4f} {corr_spearman_teste:<15.4f}")
print(f"{'P-valor Spearman':<20} {p_spearman_treino:<15.4f} {p_spearman_teste:<15.4f}")
print("=" * 60)

# InterpretaÃ§Ã£o das correlaÃ§Ãµes
print(f"\n=== INTERPRETAÃ‡ÃƒO DAS CORRELAÃ‡Ã•ES ===")
print(f"ğŸ“Š CorrelaÃ§Ã£o Treino: {corr_treino:.4f}")
if corr_treino >= 0.9:
    print("   âœ… EXCELENTE: CorrelaÃ§Ã£o muito forte")
elif corr_treino >= 0.8:
    print("   âœ… MUITO BOM: CorrelaÃ§Ã£o forte")
elif corr_treino >= 0.7:
    print("   âœ… BOM: CorrelaÃ§Ã£o moderadamente forte")
elif corr_treino >= 0.5:
    print("   âš ï¸  MODERADO: CorrelaÃ§Ã£o moderada")
else:
    print("   âŒ BAIXO: CorrelaÃ§Ã£o fraca")

print(f"\nğŸ“Š CorrelaÃ§Ã£o Teste: {corr_teste:.4f}")
if corr_teste >= 0.9:
    print("   âœ… EXCELENTE: CorrelaÃ§Ã£o muito forte")
elif corr_teste >= 0.8:
    print("   âœ… MUITO BOM: CorrelaÃ§Ã£o forte")
elif corr_teste >= 0.7:
    print("   âœ… BOM: CorrelaÃ§Ã£o moderadamente forte")
elif corr_teste >= 0.5:
    print("   âš ï¸  MODERADO: CorrelaÃ§Ã£o moderada")
else:
    print("   âŒ BAIXO: CorrelaÃ§Ã£o fraca")
```

---

## ğŸ“ PASSO 5: AnÃ¡lise e ComentÃ¡rios

```python
# Criar resumo executivo
print("\n" + "="*80)
print("ğŸ“‹ RESUMO EXECUTIVO - MODELO DE REGRESSÃƒO LINEAR")
print("="*80)

print(f"\nğŸ¯ PERFORMANCE DO MODELO:")
print(f"   â€¢ RÂ² Treino: {lr_train_r2:.4f}")
print(f"   â€¢ RÂ² Teste:  {lr_test_r2:.4f}")
print(f"   â€¢ DiferenÃ§a: {abs(lr_train_r2 - lr_test_r2):.4f}")

if abs(lr_train_r2 - lr_test_r2) < 0.05:
    print("   âœ… Modelo estÃ¡vel (pouca diferenÃ§a treino/teste)")
else:
    print("   âš ï¸  PossÃ­vel overfitting (grande diferenÃ§a treino/teste)")

print(f"\nğŸ“Š ANÃLISE DOS RESÃDUOS:")
print(f"   â€¢ MÃ©dia dos resÃ­duos: {np.mean(residuos_treino):.4f} (deve ser prÃ³xima de 0)")
print(f"   â€¢ Desvio padrÃ£o: {np.std(residuos_treino):.4f}")
print(f"   â€¢ Normalidade (Shapiro-Wilk): {'SIM' if p_value > 0.05 else 'NÃƒO'}")

print(f"\nğŸ”— CORRELAÃ‡Ã•ES:")
print(f"   â€¢ Treino: {corr_treino:.4f}")
print(f"   â€¢ Teste:  {corr_teste:.4f}")

print(f"\nğŸ’¡ INTERPRETAÃ‡ÃƒO GERAL:")
if lr_test_r2 >= 0.8 and corr_teste >= 0.8:
    print("   âœ… EXCELENTE: Modelo muito bem ajustado aos dados")
elif lr_test_r2 >= 0.7 and corr_teste >= 0.7:
    print("   âœ… BOM: Modelo bem ajustado aos dados")
elif lr_test_r2 >= 0.5 and corr_teste >= 0.5:
    print("   âš ï¸  MODERADO: Modelo com ajuste moderado")
else:
    print("   âŒ BAIXO: Modelo com ajuste insuficiente")

print("="*80)
```

---

## ğŸ¯ **RESPOSTAS AOS REQUISITOS:**

### **1. Histograma dos ResÃ­duos:**
- âœ… **Implementado** com curva normal teÃ³rica
- âœ… **Teste de normalidade** (Shapiro-Wilk)
- âœ… **QQ-Plot** para verificaÃ§Ã£o visual
- âœ… **AnÃ¡lise de assimetria e curtose**

### **2. GrÃ¡ficos de DispersÃ£o:**
- âœ… **Treino vs Teste** lado a lado
- âœ… **Linha de perfeita prediÃ§Ã£o** (y=x)
- âœ… **RÂ²** exibido em cada grÃ¡fico
- âœ… **MÃ©tricas de erro** (MSE, RMSE, MAE)

### **3. Coeficientes de CorrelaÃ§Ã£o:**
- âœ… **Pearson e Spearman** para robustez
- âœ… **P-valores** para significÃ¢ncia estatÃ­stica
- âœ… **InterpretaÃ§Ã£o automÃ¡tica** dos valores
- âœ… **ComparaÃ§Ã£o treino vs teste**

### **4. AnÃ¡lise Completa:**
- âœ… **Resumo executivo** com interpretaÃ§Ãµes
- âœ… **DetecÃ§Ã£o de overfitting**
- âœ… **AvaliaÃ§Ã£o da qualidade do ajuste**
- âœ… **ComentÃ¡rios sobre gaussianidade**

---

## ğŸ’¡ **COMO USAR:**

1. **Execute cada bloco** na ordem apresentada
2. **Analise os grÃ¡ficos** gerados
3. **Leia os comentÃ¡rios** automÃ¡ticos
4. **Use o resumo executivo** para sua anÃ¡lise

Este cÃ³digo fornece uma anÃ¡lise completa e profissional do modelo de regressÃ£o linear! ğŸš€ 