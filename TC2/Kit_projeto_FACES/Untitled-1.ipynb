{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd09c67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f7c1e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_dataset_faces(dimensoes_resize, arquivo_saida, usar_pca=False, n_componentes=None):\n",
    "    \"\"\"\n",
    "    Carrega imagens de faces, as pré-processa e salva o dataset em um arquivo.\n",
    "\n",
    "    A função busca por imagens de faces em um formato de nome específico no diretório\n",
    "    atual, redimensiona cada imagem, as vetoriza, opcionalmente aplica PCA para\n",
    "    redução de dimensionalidade, e as salva com seus rótulos em um arquivo de texto.\n",
    "\n",
    "    Args:\n",
    "        dimensoes_resize (tuple): Tupla (altura, largura) para o redimensionamento. Ex: (60, 60).\n",
    "        arquivo_saida (str): Nome do arquivo de texto onde o dataset será salvo.\n",
    "        usar_pca (bool, optional): Se True, aplica PCA nos dados. Padrão é False.\n",
    "        n_componentes (int, optional): Número de componentes principais a serem mantidos.\n",
    "                                       Obrigatório se usar_pca for True.\n",
    "\n",
    "    Returns:\n",
    "        bool: True se o dataset foi criado com sucesso, False caso contrário.\n",
    "    \"\"\"\n",
    "    print(\"--- Iniciando a preparação do dataset de faces ---\")\n",
    "\n",
    "    # --- Validação de Parâmetros ---\n",
    "    if usar_pca and (n_componentes is None or n_componentes <= 0):\n",
    "        print(\"\\nErro: Se 'usar_pca' é True, 'n_componentes' deve ser um número inteiro positivo.\")\n",
    "        return False\n",
    "\n",
    "    # --- Configuração dos nomes de arquivo ---\n",
    "    part1 = 'subject0'\n",
    "    part2 = 'subject'\n",
    "    part3 = [\n",
    "        '.centerlight', '.glasses', '.happy', '.leftlight', '.noglasses', \n",
    "        '.normal', '.rightlight', '.sad', '.sleepy', '.surprised', '.wink'\n",
    "    ]\n",
    "    Nind = 15  # Número de indivíduos (classes)\n",
    "\n",
    "    X_list = []\n",
    "    Y_list = []\n",
    "\n",
    "    # --- Loop de carregamento e processamento ---\n",
    "    print(f\"Redimensionando imagens para {dimensoes_resize[0]}x{dimensoes_resize[1]} pixels...\")\n",
    "    for i in range(1, Nind + 1):\n",
    "        for expression in part3:\n",
    "            if i < 10:\n",
    "                nome = f\"{part1}{i}{expression}\"\n",
    "            else:\n",
    "                nome = f\"{part2}{i}{expression}\"\n",
    "            \n",
    "            if not os.path.exists(nome):\n",
    "                continue\n",
    "\n",
    "            img = cv2.imread(nome, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            ar = cv2.resize(img, (dimensoes_resize[1], dimensoes_resize[0]))\n",
    "            a_mat = ar.astype(np.float64) / 255.0\n",
    "            a_vec = a_mat.flatten(order='F')\n",
    "            rot = i\n",
    "\n",
    "            X_list.append(a_vec)\n",
    "            Y_list.append(rot)\n",
    "    \n",
    "    # --- Verificação e montagem do dataset ---\n",
    "    if not X_list:\n",
    "        print(\"\\nErro: Nenhuma imagem foi encontrada. O dataset não foi gerado.\")\n",
    "        return False\n",
    "\n",
    "    X = np.array(X_list)\n",
    "    Y = np.array(Y_list).reshape(-1, 1)\n",
    "\n",
    "    # --- Etapa opcional de PCA ---\n",
    "    if usar_pca:\n",
    "        # Verifica se o número de componentes não é maior que o número de amostras\n",
    "        if n_componentes > X.shape[0]:\n",
    "            print(f\"\\nAviso: O número de componentes ({n_componentes}) é maior que o número de amostras ({X.shape[0]}).\")\n",
    "            print(f\"Ajustando o número de componentes para {X.shape[0]}.\")\n",
    "            n_componentes = X.shape[0]\n",
    "\n",
    "        print(f\"\\nAplicando PCA para reduzir a dimensionalidade para {n_componentes} componentes...\")\n",
    "        pca = PCA(n_components=n_componentes)\n",
    "        X = pca.fit_transform(X) # fit_transform espera amostras como linhas\n",
    "        print(f\"Dimensionalidade reduzida. Novo formato das features: {X.shape}\")\n",
    "\n",
    "    # Combina features (X) e rótulo (Y) em uma única matriz Z\n",
    "    Z = np.hstack((X, Y))\n",
    "\n",
    "    # --- Salvamento do arquivo ---\n",
    "    try:\n",
    "        np.savetxt(arquivo_saida, Z, fmt='%.8f')\n",
    "        print(f\"\\nProcessamento completo.\")\n",
    "        print(f\"Dataset com {Z.shape[0]} amostras e {Z.shape[1]} colunas salvo em '{arquivo_saida}'.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"\\nErro ao salvar o arquivo: {e}\")\n",
    "        return False\n",
    "\n",
    "def executar_analise_modelos(nome_arquivo):\n",
    "    \"\"\"\n",
    "    Executa uma análise comparativa de modelos de regressão para uma tarefa de classificação.\n",
    "\n",
    "    A função carrega os dados de um arquivo, executa uma validação cruzada de 5 folds\n",
    "    para cada modelo, calcula estatísticas de acurácia e tempo, e imprime uma\n",
    "    tabela de resultados formatada no console.\n",
    "\n",
    "    Args:\n",
    "        nome_arquivo (str): O caminho para o arquivo de dados (ex: 'recfaces.dat').\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame or None: Um DataFrame contendo os resultados compilados da análise,\n",
    "                                  ou None se o arquivo de dados não for encontrado.\n",
    "    \"\"\"\n",
    "    # --- Configuração Inicial ---\n",
    "    # Ignorar avisos para manter a saída limpa\n",
    "    from sklearn.exceptions import ConvergenceWarning\n",
    "    warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "\n",
    "    # --- Carregar os Dados ---\n",
    "    try:\n",
    "        print(f\"Carregando o arquivo '{nome_arquivo}'...\")\n",
    "        data = np.loadtxt(nome_arquivo)\n",
    "        X = data[:, :-1]\n",
    "        y = data[:, -1]\n",
    "        print(f\"Dados carregados: {X.shape[0]} amostras, {X.shape[1]} features.\")\n",
    "        print(\"-\" * 50)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erro: O arquivo '{nome_arquivo}' não foi encontrado.\")\n",
    "        return None\n",
    "\n",
    "    # --- Definir os Modelos de Regressão ---\n",
    "    regressors = {\n",
    "        \"MQ\": LinearRegression(),\n",
    "        \"PL\": MLPRegressor(hidden_layer_sizes=(), activation='relu',\n",
    "                                                  max_iter=100000, random_state=2,solver='sgd'),\n",
    "        \"MLP-1H\": MLPRegressor(hidden_layer_sizes=(10,), activation='relu',\n",
    "                                              max_iter=100000, random_state=2,solver='sgd'),\n",
    "        \"MLP-2H\": MLPRegressor(hidden_layer_sizes=(10, 10), activation='relu',\n",
    "                                                 max_iter=10000, random_state=2,solver='sgd')\n",
    "    }\n",
    "\n",
    "    # --- Preparação para Coletar Resultados ---\n",
    "    results_list = []\n",
    "\n",
    "    # --- Loop de Execução e Avaliação com Validação Cruzada ---\n",
    "    for name, model in regressors.items():\n",
    "        print(f\"Avaliando o modelo: {name}...\")\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('regressor', model)\n",
    "        ])\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        fold_accuracies = []\n",
    "        fold_iterations = []\n",
    "        fold_times = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "            start_fold_time = time.time()\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "            pipeline.fit(X_train, y_train)\n",
    "            y_pred_continuous = pipeline.predict(X_test)\n",
    "            y_pred_class = np.round(y_pred_continuous)\n",
    "            y_pred_class = np.clip(y_pred_class, 1, 15)\n",
    "            \n",
    "            end_fold_time = time.time()\n",
    "            \n",
    "            fold_accuracies.append(accuracy_score(y_test, y_pred_class))\n",
    "            fold_times.append(end_fold_time - start_fold_time)\n",
    "\n",
    "            if hasattr(pipeline.named_steps['regressor'], 'n_iter_'):\n",
    "                fold_iterations.append(pipeline.named_steps['regressor'].n_iter_)\n",
    "\n",
    "        result_dict = {\n",
    "            'Classificador': name,\n",
    "            'Acurácia Média': np.mean(fold_accuracies),\n",
    "            'Acurácia Mín': np.min(fold_accuracies),\n",
    "            'Acurácia Máx': np.max(fold_accuracies),\n",
    "            'Desvio Padrão': np.std(fold_accuracies),\n",
    "            'Tempo Médio / Fold (s)': np.mean(fold_times),\n",
    "            'Iterações (Média)': np.mean(fold_iterations) if fold_iterations else np.nan\n",
    "        }\n",
    "        \n",
    "        results_list.append(result_dict)\n",
    "\n",
    "    # --- Apresentação Final dos Resultados ---\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"--- Tabela de Resultados (Validação Cruzada com 5 Folds) ---\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    pd.options.display.float_format = '{:,.4f}'.format\n",
    "    results_df = results_df.rename(columns={\n",
    "        'Acurácia Média': 'Média',\n",
    "        'Acurácia Mín': 'Mínimo',\n",
    "        'Acurácia Máx': 'Máximo'\n",
    "    })\n",
    "\n",
    "    # print(results_df[[\n",
    "    #     'Classificador', 'Média', 'Mínimo', 'Máximo', 'Desvio Padrão', \n",
    "    #     'Tempo Médio / Fold (s)', 'Iterações (Média)'\n",
    "    # ]].to_string(index=False))\n",
    "    \n",
    "    # Retorna o DataFrame para uso posterior, se necessário\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d6901f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando a preparação do dataset de faces ---\n",
      "Redimensionando imagens para 60x60 pixels...\n",
      "\n",
      "Processamento completo.\n",
      "Dataset com 165 amostras e 3601 colunas salvo em 'recfaces_60x60_sem_pca.dat'.\n",
      "Carregando o arquivo 'recfaces_60x60_sem_pca.dat'...\n",
      "Dados carregados: 165 amostras, 3600 features.\n",
      "--------------------------------------------------\n",
      "Avaliando o modelo: MQ...\n",
      "Avaliando o modelo: PL...\n",
      "Avaliando o modelo: MLP-1H...\n",
      "Avaliando o modelo: MLP-2H...\n",
      "\n",
      "======================================================================\n",
      "--- Tabela de Resultados (Validação Cruzada com 5 Folds) ---\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classificador</th>\n",
       "      <th>Média</th>\n",
       "      <th>Mínimo</th>\n",
       "      <th>Máximo</th>\n",
       "      <th>Desvio Padrão</th>\n",
       "      <th>Tempo Médio / Fold (s)</th>\n",
       "      <th>Iterações (Média)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MQ</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PL</td>\n",
       "      <td>0.3576</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.4242</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.1692</td>\n",
       "      <td>423.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP-1H</td>\n",
       "      <td>0.4485</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.6061</td>\n",
       "      <td>0.1124</td>\n",
       "      <td>0.1734</td>\n",
       "      <td>173.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP-2H</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.4848</td>\n",
       "      <td>0.0624</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>167.8000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classificador  Média  Mínimo  Máximo  Desvio Padrão  Tempo Médio / Fold (s)  \\\n",
       "0            MQ 0.3333  0.2727  0.3636         0.0332                  0.0220   \n",
       "1            PL 0.3576  0.3030  0.4242         0.0555                  0.1692   \n",
       "2        MLP-1H 0.4485  0.3030  0.6061         0.1124                  0.1734   \n",
       "3        MLP-2H 0.3818  0.3030  0.4848         0.0624                  0.1379   \n",
       "\n",
       "   Iterações (Média)  \n",
       "0                NaN  \n",
       "1           423.6000  \n",
       "2           173.8000  \n",
       "3           167.8000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preparar_dataset_faces(dimensoes_resize=(60, 60), arquivo_saida='recfaces_60x60_sem_pca.dat', usar_pca=False)\n",
    "executar_analise_modelos('recfaces_60x60_sem_pca.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21698bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando a preparação do dataset de faces ---\n",
      "Redimensionando imagens para 60x60 pixels...\n",
      "\n",
      "Aplicando PCA para reduzir a dimensionalidade para 20 componentes...\n",
      "Dimensionalidade reduzida. Novo formato das features: (165, 20)\n",
      "\n",
      "Processamento completo.\n",
      "Dataset com 165 amostras e 21 colunas salvo em 'recfaces_60x60_com_pca.dat'.\n",
      "Carregando o arquivo 'recfaces_60x60_com_pca.dat'...\n",
      "Dados carregados: 165 amostras, 20 features.\n",
      "--------------------------------------------------\n",
      "Avaliando o modelo: MQ...\n",
      "Avaliando o modelo: PL...\n",
      "Avaliando o modelo: MLP-1H...\n",
      "Avaliando o modelo: MLP-2H...\n",
      "\n",
      "======================================================================\n",
      "--- Tabela de Resultados (Validação Cruzada com 5 Folds) ---\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classificador</th>\n",
       "      <th>Média</th>\n",
       "      <th>Mínimo</th>\n",
       "      <th>Máximo</th>\n",
       "      <th>Desvio Padrão</th>\n",
       "      <th>Tempo Médio / Fold (s)</th>\n",
       "      <th>Iterações (Média)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MQ</td>\n",
       "      <td>0.2242</td>\n",
       "      <td>0.0606</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0951</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PL</td>\n",
       "      <td>0.2121</td>\n",
       "      <td>0.0606</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>440.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP-1H</td>\n",
       "      <td>0.4303</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4848</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.2562</td>\n",
       "      <td>1,890.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP-2H</td>\n",
       "      <td>0.4303</td>\n",
       "      <td>0.4242</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.1813</td>\n",
       "      <td>1,236.6000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classificador  Média  Mínimo  Máximo  Desvio Padrão  Tempo Médio / Fold (s)  \\\n",
       "0            MQ 0.2242  0.0606  0.3333         0.0951                  0.0008   \n",
       "1            PL 0.2121  0.0606  0.3030         0.0857                  0.0263   \n",
       "2        MLP-1H 0.4303  0.3333  0.4848         0.0555                  0.2562   \n",
       "3        MLP-2H 0.4303  0.4242  0.4545         0.0121                  0.1813   \n",
       "\n",
       "   Iterações (Média)  \n",
       "0                NaN  \n",
       "1           440.2000  \n",
       "2         1,890.8000  \n",
       "3         1,236.6000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preparar_dataset_faces(dimensoes_resize=(60, 60), arquivo_saida='recfaces_60x60_com_pca.dat', usar_pca=True, n_componentes=20)\n",
    "executar_analise_modelos('recfaces_60x60_com_pca.dat')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
